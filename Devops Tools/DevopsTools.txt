DAY1: Containerization (Docker):

Docker:it is isolated environment with libraries ,application runtime and dependencies.It is lightweight sandbox environment.Everything that is required to run an application like (Build->ship->run)

Understanding Containers V/S Virtual Machines:
Containers:The underlying hardware is physical server,it has only one OS runs on the host machines ,container engine like software like docker or kubernets that manages containers.each container include only the application and its dependencies but share the host OS kernels .
Virtual Machines:It has physical hardware like server storage networking.The OS installed on the physical machines eg window,linux.software like VMware ,virtual box that creates and manages multiple VMs and in guest OS ech vm runs its owns operating system which increases overhead ,and each VM has its own library binaries and dependencies to run application

Containers V/S Virtual machines with the help of a Building and House analogy:
Containers(Building):it is like shared but infrastructure isolated system 
Virtual Machines(House):it is like operating system isolated infrastructure.

A Simple Docker WorkFlow:
It starts with a writing a docker file ,which defines the application environment,including the base OS,dependencies and commands to run the application.next you build docker image using docker build,which packages everything into a reusable format then you run a container from this image using docker run which launches the application in an isolated environment.if needed you can push the image to docker hub for sharing or deployment.finally to manage multiple containers you can use docker compose or kubernets for scalling and automations.

Docker Architecture:
It follows a client server Architecture,the docker client interacts with the docker daemon,which manages container,images networks and storage .the docker daemon runs in the background on the host machine and listens for the command from the client.the docker engine is the core componenet that include daemon,CLI,and API.images are light weight standalone packages contaning application code dependencies and configurations.when an image runs it creates a container an isolated runtime environment.docker also uses registries like docker hub to store share images .this Architecture makes application portable scalable and efficient.

DAY2:How To Dockerize a Project 
Get started
Clone a sample git repository using the below command or use your project for the demo:
cd into the directory
Create an empty file with the name Dockerfile=touch Dockerfile
Using the text editor of your choice, paste the below content ( Details about each of these have already shared in the video):
FROM node:18-alpine
WORKDIR /app
COPY . .
RUN yarn install --production
CMD ["node", "src/index.js"]
EXPOSE 3000

Build the docker image using the application code and Dockerfile=docker build -t day02-todo .

Verify the image has been created and stored locally using the below command:docker images

Create a public repository on hub.docker.com and push the image to remote repo:
docker login
docker tag day02-todo:latest username/new-reponame:tagname
docker images
docker push username/new-reponame:tagname

To pull the image to another environment , you can use below command
docker pull username/new-reponame:tagname

To start the docker container, use below command
docker run -dp 3000:3000 username/new-reponame:tagname

Verify your app. If you have followed the above steps correctly, your app should be listening on localhost:3000
To enter(exec) into the container, use the below command
docker exec -it containername sh
or
docker exec -it containerid sh

To view docker logs
docker logs containername
or
docker logs containerid



DAY3:
Getting started with the demo:Clone the below sample repository, or you can use any web application that you have=git clone https://github.com/piyushsachdeva/todoapp-docker.git
cd into the directory
cd todoapp-docker/
Create an empty file with the name Dockerfile=touch Dockerfile
Using the text editor of your choice, paste the below content: Note: Details about the below Dockerfile have already been shared in the video=FROM node:18-alpine AS installer
WORKDIR /app
COPY package*.json ./
RUN npm install 
COPY . .
RUN npm run build
FROM nginx:latest AS deployer
COPY --from=installer /app/build /usr/share/nginx/html
Build the docker image using the application code and Dockerfile
docker build -t todoapp-docker .
Verify the image has been created and stored locally using the below command:
docker images
Create a public repository on hub.docker.com and push the image to remote repo
docker login
docker tag todoapp-docker:latest username/new-reponame:tagname
docker images
docker push username/new-reponame:tagname
To pull the image to another environment, you can use the below command
docker pull username/new-reponame:tagname
To start the docker container, use the below command
docker run -dp 3000:80 username/new-reponame:tagname
Verify your app. If you have followed the above steps correctly, your app should be listening on localhost:3000
To enter(exec) into the container, use the below command
docker exec -it containername sh
or
docker exec -it containerid sh
To view docker logs
docker logs containername
or
docker logs containerid
To view the content of Docker container
docker inspect
Cleanup the old docker images from local repo using below command:
docker image rm image-id


DAY4:
Challenges of Using Standalone Containers:
1.Manual scaling-you have to manually start,stop,scale containers based on demand.
2.Networking complexity:Managing communication between multiple containers is difficult.
3.Load Balancing:Traffic distribution across multiple containers requires manual setup
4.Fault Tolerance:No built in mechanism to restart failed containers or distribute workloads.


How Kubernetes Solves These Challenges :
1.Automated scaling:Uses the horizontal pod autoscaler to adjust container replicas based on cpu/memory usage.
2.Built-in Networking – Provides service discovery and inter-container communication via kube-proxy and networking policies.
3.Load Balancing – Uses Services to automatically distribute traffic among multiple container instances.


5 Use Cases Where You Should Use Kubernetes 
Microservices Architecture – Ideal for managing multiple interdependent services.
Auto-Scaling Applications – Automatically scales applications based on load.
Multi-Cloud Deployments – Works across AWS, Azure, GCP, and on-premises.
CI/CD Pipelines – Supports automated software deployments.
Big Data & AI Workloads – Handles distributed computing with Spark, TensorFlow, etc.



5 Use Cases Where You Should NOT Use Kubernetes 
Small-Scale Applications – Overhead is too high for simple apps.
Monolithic Applications – Legacy apps that don’t benefit from containerization.
Resource-Constrained Environments – Not suitable for low-power devices or small VMs.
Low-Latency Real-Time Systems – Kubernetes introduces some delay due to orchestration overhead.
Short-Lived Batch Jobs – Simpler container solutions like Docker Swarm may be better.

DAY5:

Kubernetes Architecture Overview:
Kubernetes is a container orchestration platform designed to manage, scale, and automate containerized applications. Its architecture follows a Master-Worker model, where the Control Plane (Master Node) manages the cluster, and Worker Nodes run the actual applications.

1. Control Plane (Master Node) – Brain of Kubernetes
The Control Plane manages the cluster and ensures the desired state of applications. It consists of:

1️⃣ API Server (kube-apiserver)

Acts as the entry point for all Kubernetes operations.
Receives REST API requests and processes them.
2️⃣ Controller Manager (kube-controller-manager)

Monitors and maintains the cluster’s state (e.g., scaling, node health).
Includes controllers like ReplicaSet, Node, and Job controllers.
3️⃣ Scheduler (kube-scheduler)

Assigns Pods to Worker Nodes based on resource availability and constraints.
4️⃣ ETCD (Distributed Key-Value Store)

Stores cluster configuration and state information.
Highly available and consistent database.


 2. Worker Nodes – Runs Applications (Pods & Containers)
Worker Nodes run application workloads and are managed by the Control Plane. Each node has:

1️⃣ Kubelet

Agent running on each worker node.
Ensures containers are running as expected.
2️⃣ Container Runtime (Docker, containerd, CRI-O)

Executes and manages containers.
3️⃣ Kube Proxy (kube-proxy)

Handles networking and communication between services.
Manages network routing for Pods.
4️⃣ Pods

The smallest deployable unit in Kubernetes.
Contains one or more containers.


Other Important Kubernetes Components
✅ Namespaces – Logical separation of resources within a cluster.
✅ ConfigMaps & Secrets – Stores configuration and sensitive data.
✅ Persistent Volumes (PVs) & Persistent Volume Claims (PVCs) – Provides persistent storage.
✅ Ingress Controller – Manages external access to services using domain names.

How Kubernetes Works?
1️⃣ User interacts with the API Server (via kubectl, UI, or API).
2️⃣ Scheduler assigns workloads (Pods) to Worker Nodes.
3️⃣ Kubelet ensures containers run on the assigned nodes.
4️⃣ Kube Proxy manages networking between Pods and external users.
5️⃣ Controller Manager ensures the desired state (self-healing, scaling, etc.).


DAY6:
first learn to install kubectl,and kind cluster .
Below domains and all of its sub-domains are allowed to be referred in the exam

https://kubernetes.io/docs
https://kubernetes.io/blog/
Kubernetes cheat sheet : https://kubernetes.io/docs/reference/kubectl/quick-reference/


DAY7:

Different ways of creating a Kubernetes object
Imperative way ( Through command or API calls)
Declarative way ( By creating manifest files)
Below is the sample pod YAML used in the video:
# This is a sample pod yaml

apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    env: demo
    type: frontend
spec:
  containers:
  - name: nginx-container
    image: nginx
    ports:
    - containerPort: 80